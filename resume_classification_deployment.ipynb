{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65eeadf-55ef-4bc4-9cf9-71b3b7fb3298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b792d4de-6622-4da7-b892-5605dc989d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = pickle.load(open(\"modelDT.pkl\", 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752febff-914b-4938-90ff-65a8cb31fd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2024-11-27 21:34:57.062 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import re\n",
    "import docx2txt\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import pickle as pk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Initialize NLTK resources\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load your model and vectorizer\n",
    "model = pk.load(open('modelDT.pkl', 'rb'))\n",
    "Vectorizer = pk.load(open('vector.pkl', 'rb'))\n",
    "\n",
    "# Title of the application\n",
    "st.title('Resume Classification')\n",
    "st.markdown('<style>h1{color: Purple;}</style>', unsafe_allow_html=True)\n",
    "st.subheader('Upload your resumes in PDF or DOCX format')\n",
    "\n",
    "# Function to extract text from uploaded files\n",
    "def getText(doc_file):\n",
    "    fullText = ''\n",
    "    if doc_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
    "        fullText = docx2txt.process(doc_file)\n",
    "    elif doc_file.type == \"application/pdf\":\n",
    "        with pdfplumber.open(doc_file) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_content = page.extract_text()\n",
    "                if page_content:\n",
    "                    fullText += page_content\n",
    "    return fullText\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    sentence = str(text)\n",
    "    sentence = sentence.lower()\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url = re.sub(r'http\\S+', '', cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 and w not in stopwords.words('english')]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words = [lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "    return \" \".join(lemma_words) \n",
    "\n",
    "# File uploader\n",
    "upload_file = st.file_uploader('Upload Your Resumes', type=['docx', 'pdf'], accept_multiple_files=True)\n",
    "\n",
    "# Initialize data structures\n",
    "filename = []\n",
    "predicted = []\n",
    "skills = []\n",
    "\n",
    "if upload_file:\n",
    "    for doc_file in upload_file:\n",
    "        if doc_file is not None:\n",
    "            # Extract text from the uploaded file\n",
    "            extText = getText(doc_file)\n",
    "            cleaned_text = preprocess(extText)\n",
    "\n",
    "            # Predict the profile\n",
    "            # Assuming you have a function to make predictions\n",
    "            # For demonstration, we will use a simple model prediction\n",
    "            # You may need to transform the cleaned text using your Vectorizer\n",
    "            prediction = model.predict(Vectorizer.transform([cleaned_text]))\n",
    "            predicted.append(prediction[0])  # Assuming the prediction returns a list\n",
    "            filename.append(doc_file.name)\n",
    "            skills.append(\"Extracted Skills\")  # Replace with actual skill extraction logic\n",
    "\n",
    "    # Create a DataFrame to display the results\n",
    "    file_type = pd.DataFrame({\n",
    "        'Uploaded File': filename,\n",
    "        'Skills': skills,\n",
    "        'Predicted Profile': predicted\n",
    "    })\n",
    "\n",
    "    # Display the results in a table\n",
    "    if len(predicted) > 0:\n",
    "        st.table(file_type.style.format())\n",
    "\n",
    "    # Selection for filtering profiles\n",
    "    select = ['PeopleSoft', 'SQL Developer', 'React JS Developer', 'Workday']\n",
    "    st.subheader('Select as per Requirement')\n",
    "    option = st.selectbox('Fields', select)\n",
    "\n",
    "    # Filter and display results based on selection\n",
    "    if option in file_type['Predicted Profile'].values:\n",
    "        st.table(file_type[file_type['Predicted Profile'] == option])\n",
    "    else:\n",
    "        st.write(\"No resumes found for the selected profile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59131a61-66c3-495c-aa88-d5d72ccae5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
